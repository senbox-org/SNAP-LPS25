{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24438183-d726-485c-8494-58aca7811a79",
   "metadata": {},
   "source": [
    "# **LPS - Workflow Example**\n",
    "\n",
    "In summary, this workflow contains:\n",
    "\n",
    "- Setup access to S3\n",
    "- Catalogue search using STAC API\n",
    "- Download a Sentinel-2 data product from S3\n",
    "- Briefly explore the product\n",
    "- Run a simple SNAP workflow (Read, Subset, BandMath (NDVI)) in three ways:\n",
    "  - use the Java-Python mapping provided by Snappy\n",
    "  - use SNAP GPF operators with Snappy\n",
    "  - create and execute a SNAP GPF xml graph using SNAPISTA \n",
    "- Cleanup\n",
    "\n",
    "- ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b10c7c-5c44-4769-8fa0-44abb27cfead",
   "metadata": {},
   "source": [
    "## **1. Import Python packages**\n",
    "\n",
    "**Note:** The imports of *esa_snappy* and *snapista* may result in various Info/Warning/Error messages from SNAP core or 3rd party modules. They can be ignored here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e0700d-a086-4c26-81a9-231a1bf42ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import sysconfig\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# S3 API\n",
    "import boto3\n",
    "\n",
    "# esa_snappy\n",
    "import esa_snappy\n",
    "\n",
    "# Snapista\n",
    "import snapista\n",
    "from snapista import Graph\n",
    "from snapista import Operator\n",
    "from snapista import TargetBand\n",
    "from snapista import TargetBandDescriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e909bd-64a9-4069-8d21-f0b6a1734840",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b62a2-4728-481c-9125-a60bc2a69fc4",
   "metadata": {},
   "source": [
    "## **2. Get credentials for S3 access**\n",
    "\n",
    "**Note:** Before using this NB for the first time in a new server, create a text file '.env' in your home directory with two lines giving your CDSE username/password:\n",
    "```\n",
    "CDSE_USERNAME=myusername\n",
    "CDSE_PASSWORD=mypassword\n",
    "```\n",
    "\n",
    "Basically, credentials for S3 access can be created in the [S3 keys manager dashboard](https://eodata-s3keysmanager.dataspace.copernicus.eu/panel/s3-credentials).\n",
    "(This does not seem to work correctly for everyone: ok for PL, but not for OD. TODO: investigate)\n",
    "\n",
    "Below we follow an approach using temporary credentials which will be deleted when no longer needed.\n",
    "See details at [https://documentation.dataspace.copernicus.eu/APIs/S3.html#example-script-to-download-product-using-python](https://documentation.dataspace.copernicus.eu/APIs/S3.html#example-script-to-download-product-using-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77de28e-3fc7-4bdf-88b0-51bcbb13642c",
   "metadata": {},
   "source": [
    "##### ***Configuration parameters:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9f68c-b5e4-4e54-bd39-7e9f66fbe071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"auth_server_url\": \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\",\n",
    "    \"odata_base_url\": \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products\",\n",
    "    \"s3_endpoint_url\": \"https://eodata.dataspace.copernicus.eu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1907169e-02cb-4687-817e-df0ae6dfb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "username = os.getenv('CDSE_USERNAME')\n",
    "password = os.getenv('CDSE_PASSWORD')\n",
    "#print(username)\n",
    "#print(password)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96687ea-45db-4598-b1e8-27fd6ff41da5",
   "metadata": {},
   "source": [
    "##### ***Retrieve an access token:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6a7ee-9a8d-4556-975e-0f7d69e69701",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "def get_access_token(config, username, password):\n",
    "    \"\"\"\n",
    "    Retrieve an access token from the authentication server.\n",
    "    This token is used for subsequent API calls.\n",
    "    \"\"\"\n",
    "    auth_data = {\n",
    "        \"client_id\": \"cdse-public\",\n",
    "        \"grant_type\": \"password\",\n",
    "        \"username\": username,\n",
    "        \"password\": password,\n",
    "    }\n",
    "    response = requests.post(config[\"auth_server_url\"], data=auth_data, verify=True, allow_redirects=False)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.text)[\"access_token\"]\n",
    "    else:\n",
    "        print(f\"Failed to retrieve access token. Status code: {response.status_code}\")\n",
    "        exit(1)\n",
    "\n",
    "###################################################################################################\n",
    "access_token = get_access_token(config, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cfdfb-775e-443d-ab7e-efaf59ca0d39",
   "metadata": {},
   "source": [
    "##### ***Set up headers for API calls:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f8eb6-3a4a-48f0-9de6-4374f55e9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea23689-0353-47d2-8cc9-fd791d6d8d04",
   "metadata": {},
   "source": [
    "##### ***Create temporary S3 credentials:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2115ad-b946-4303-b637-3a9dc88ad73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "def get_temporary_s3_credentials(headers):\n",
    "    \"\"\"\n",
    "    Create temporary S3 credentials by calling the S3 keys manager API.\n",
    "    \"\"\"\n",
    "    credentials_response = requests.post(\"https://s3-keys-manager.cloudferro.com/api/user/credentials\", headers=headers)\n",
    "    if credentials_response.status_code == 200:\n",
    "        s3_credentials = credentials_response.json()\n",
    "        print(\"Temporary S3 credentials created successfully.\")\n",
    "        #print(f\"access: {s3_credentials['access_id']}\")\n",
    "        #print(f\"secret: {s3_credentials['secret']}\")\n",
    "        return s3_credentials\n",
    "    else:\n",
    "        print(f\"Failed to create temporary S3 credentials. Status code: {credentials_response.status_code}\")\n",
    "        print(\"Product download aborted.\")\n",
    "        exit(1)\n",
    "\n",
    "###################################################################################################\n",
    "s3_credentials = get_temporary_s3_credentials(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa89796-2c0f-49de-81d3-7148d9293c31",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781be85f-4f6a-4773-a719-3c0f2cdb30fa",
   "metadata": {},
   "source": [
    "## **3. Set up area and time interval of interest**\n",
    "The bounding box in `WGS84` coordinate system is `[(longitude and latitude coordinates of lower left and upper right corners)]`. \n",
    "You can get the bbox for a different area at the [bboxfinder](http://bboxfinder.com/) website.\n",
    "\n",
    "All requests require a bounding box to be given as an instance of `sentinelhub.geometry.BBox` with corresponding Coordinate Reference System (`sentinelhub.constants.CRS`). In our case it is in WGS84 and we can use the predefined WGS84 coordinate reference system from `sentinelhub.constants.CRS`.\n",
    "\n",
    "The selected area and time interval below will find just one product from the search: S2A_MSIL1C_20180803T103021_N0206_R108_T32UNE_20180803T142136, which includes the Hamburg area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7043be55-c11c-4ab2-bebd-f787996a01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_coords_wgs84 = [9.8, 53.45, 10.25, 53.6]\n",
    "resolution = 60\n",
    "\n",
    "# Define a time interval of just 1 day:\n",
    "time_interval = \"2018-08-03\", \"2018-08-04\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46542042-db73-409b-a0a9-19130d9d6560",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef041bc-003c-47b1-8fcc-42c7862f31c7",
   "metadata": {},
   "source": [
    "## **4. Catalog API: init catalog and do the search**\n",
    "To search and discover data, we use the Catalog API. Sentinel Hub Catalog API (or shortly \"Catalog\") is an API implementing the STAC Specification, providing geospatial information for data available in Sentinel Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac786fc5-7643-4891-a893-991f26016483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from pathlib import Path\n",
    "\n",
    "catalog = Client.open('https://stac.dataspace.copernicus.eu/v1')\n",
    "collection = catalog.get_collection(\"sentinel-2-l1c\")\n",
    "collection.title\n",
    "\n",
    "itemsearch = catalog.search(\n",
    "    collections=[\"sentinel-2-l1c\"],\n",
    "    bbox=aoi_coords_wgs84,\n",
    "    datetime=[time_interval[0], time_interval[1]],\n",
    "\n",
    ")\n",
    "\n",
    "msil1c_results = list(itemsearch.items())\n",
    "base_s3_path = str(Path(msil1c_results[0].assets[\"product_metadata\"].href).parent)\n",
    "base_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f23e0-82bd-471b-a317-a52edd57ed54",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75649a8-4e99-43da-a5da-b49dfd2fc170",
   "metadata": {},
   "source": [
    "## **5. Download L1C SAFE product from S3**\n",
    "\n",
    "In this step, the product found from the search above is downloaded as file. This is necessary because the SNAP API needs a file representation of an input product.\n",
    "\n",
    "The download progress of each file of the SAFE product will be shown below. \n",
    "\n",
    "**Note:** Sometimes this step results in a '403 Forbidden' on CDSE Jupyter Hub. In that case just try to repeat... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0561752d-0343-44b4-8b7e-84b7885f4ea8",
   "metadata": {},
   "source": [
    "##### ***Provide temporary credentials to S3 and get access:***\n",
    "\n",
    "With valid credentials, access to S3 is provided via a `boto3.resource(...)` object, where boto3 is the AWS SDK for Python. More details can be found [here](https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a772871-4288-4402-af62-b3991b86effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource=boto3.resource('s3',aws_access_key_id=s3_credentials[\"access_id\"], aws_secret_access_key=s3_credentials[\"secret\"], endpoint_url=config[\"s3_endpoint_url\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3de97a-32aa-4444-98cf-83b078664aa9",
   "metadata": {},
   "source": [
    "##### ***Alternative way to create S3 credentials:***\n",
    "\n",
    "Instead of creating temporary S3 credentials (the approach in this notebook), pairs of permanent S3 credentials could be created at the S3 keys manager:\n",
    "\n",
    "[https://eodata-s3keysmanager.dataspace.copernicus.eu/panel](https://eodata-s3keysmanager.dataspace.copernicus.eu/panel)\n",
    "\n",
    "You need to login with CDSE username/password and follow the instructions. The credentials created could then be hardcoded in the notebook like this:\n",
    "\n",
    "```python\n",
    "#access_key = \"FTYYWO2P1PTFM6GAITEM\"\n",
    "#secret_key = \"fX1pxkSPUwx2kpFiCNMK1Y9rdTML58Uf4nQDNQgh\"\n",
    "#s3_resource=boto3.resource('s3',aws_access_key_id=access_key, aws_secret_access_key=secret_key, endpoint_url=config[\"s3_endpoint_url\"])\n",
    "```\n",
    "\n",
    "or alternatively saved in the .env file, like:\n",
    "\n",
    "```\n",
    "S3_ACCESS_KEY=myaccesskey\n",
    "S3_SECRET_KEY=mysecretkey\n",
    "```\n",
    "\n",
    "and accessed as shown above for username/password.\n",
    "\n",
    "Using this approach, the functions for creating/deleting temporary S3 credentials could be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa24006-02f7-46cc-ac80-faa6f2b2e189",
   "metadata": {},
   "source": [
    "##### ***Download the data files:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53e591d-10bf-4985-b1cc-23a2b48f696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm  # For proper use in Jupyter NB, use tqdm.notebook instead of tqdm!! See https://www.datacamp.com/tutorial/tqdm-python\n",
    "\n",
    "##################################################################\n",
    "\n",
    "# For processing, download S2 MSIL1C SAFE product from result list found above:\n",
    "l1c_product_to_process = msil1c_results[0]\n",
    "print(\"Product ID: \" + l1c_product_to_process.id)\n",
    "product_path = str(Path(l1c_product_to_process.assets[\"product_metadata\"].href).parent)\n",
    "\n",
    "prefix_length = len(\"s3://\") if product_path.startswith(\"s3://\") else len(\"s3:/\")\n",
    "bucketname = product_path[prefix_length : product_path.find(\"/\", prefix_length)]  # 'EODATA'\n",
    "prefix_length = prefix_length + len(bucketname) + 1\n",
    "\n",
    "bucket=s3_resource.Bucket(bucketname)\n",
    "\n",
    "target = \"./\"\n",
    "l1c_product_to_process = product_path[prefix_length:] # e.g. \"Sentinel-2/MSI/L1C_N0500/2018/08/03/S2A_MSIL1C_20180803T103021_N0500_R108_T32UNE_20230730T062418.SAFE/\"\n",
    "#print(\"l1c_product_to_process: \" + l1c_product_to_process)\n",
    "\n",
    "l1c_files = bucket.objects.filter(Prefix=l1c_product_to_process)\n",
    "list(l1c_files)\n",
    "if not list(l1c_files):\n",
    "    raise FileNotFoundError(f\"Could not find any files for {l1c_product_to_process}\")\n",
    "\n",
    "failed_downloads = []\n",
    "for file in l1c_files:\n",
    "    os.makedirs(os.path.dirname(file.key), exist_ok=True)\n",
    "\n",
    "    client = s3_resource.meta.client\n",
    "    s3_key = file.key\n",
    "    local_path = f\"{target}{file.key}\"\n",
    "    \n",
    "    try:\n",
    "        file_size = client.head_object(Bucket=bucketname, Key=s3_key)['ContentLength']\n",
    "        formatted_filename = os.path.basename(local_path) + ' '\n",
    "        with tqdm(total=file_size, unit='B', unit_scale=True, desc=formatted_filename, bar_format='{desc:.40}| {percentage:3.0f}% {n_fmt}/{total_fmt}B') as pbar:\n",
    "            def progress_callback(bytes_transferred):\n",
    "                pbar.update(bytes_transferred)\n",
    "    \n",
    "            client.download_file(bucketname, s3_key, local_path, Callback=progress_callback)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {s3_key}. Error: {e}\")\n",
    "        failed_downloads.append(s3_key)  # TODO: print list if length > 0\n",
    "\n",
    "if not failed_downloads:\n",
    "    print(\"Product download complete.\")\n",
    "else:\n",
    "    print(\"Product download incomplete:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9303eb61-2a8a-46d3-9f8d-663009f7d2e3",
   "metadata": {},
   "source": [
    "##### ***Delete temporary S3 credentials:***\n",
    "\n",
    "After S3 access is no longer needed, we should remove the temporary S3 credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec7592-3719-4f78-b00e-e3ae12e1c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "def delete_temporary_s3_credentials(headers):\n",
    "    \"\"\"\n",
    "    Delete temporary S3 credentials by calling the S3 keys manager API.\n",
    "    \"\"\"\n",
    "    delete_response = requests.delete(f\"https://s3-keys-manager.cloudferro.com/api/user/credentials/access_id/{s3_credentials['access_id']}\", headers=headers)\n",
    "    if delete_response.status_code == 204:\n",
    "        print(\"Temporary S3 credentials deleted successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to delete temporary S3 credentials. Status code: {delete_response.status_code}\")\n",
    "\n",
    "###################################################################################################\n",
    "delete_temporary_s3_credentials(headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9494c52a-db22-42b5-b26f-a1bf607d721d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00144b6-77c0-4cf2-bdf9-a79e079c447b",
   "metadata": {},
   "source": [
    "## **6. Explore the data product**\n",
    "\n",
    "We will below briefly explore the downloaded Sentinel-2 L1C product.\n",
    "\n",
    "A Sentinel-2 Level-1C Collection 1 product provides orthorectified Top-Of-Atmosphere (TOA) reflectance, with sub-pixel multispectral and multitemporal registration accuracy. Technical quality masks are included in the product. Some of the L1C products main characteristics are listed in the table below.\n",
    "\n",
    "| Name | Level-1C |\n",
    "|:--------|:--------|\n",
    "|  High-level Description   | Top-of-atmosphere reflectances in cartographic geometry for 13 spectral bands | \n",
    "|  Data Characteristics   |  UTM/WGS84 projection, JPEG2000 image format | \n",
    "|  DEM used   |  Copernicus DEM at 30 m  | \n",
    "|  Auxiliary Data   |  CAMS, ECMWF  | \n",
    "|  Data Volume   |  700 MB (each 100x100 km2)  | \n",
    "\n",
    "L1C Products are a compilation of elementary granules of fixed size, within a single orbit. A granule is the minimum indivisible partition of a product (containing all possible spectral bands). For Level-1C and Level-2A, the granules, also called tiles, are 100x100km2 ortho-images in UTM/WGS84 projection. The UTM (Universal Transverse Mercator) system divides the Earth’s surface into 60 zones. Each UTM zone has a vertical width of 6° of longitude and horizontal width of 8° of latitude. Tiles are approximately 700 MB in size. Tiles can be fully or partially covered by image data.\n",
    "\n",
    "Many more details and further links can be found at:\n",
    "\n",
    "[https://sentinels.copernicus.eu/sentinel-data-access/sentinel-products/sentinel-2-data-products/collection-1-level-1c](https://sentinels.copernicus.eu/sentinel-data-access/sentinel-products/sentinel-2-data-products/collection-1-level-1c)\n",
    "\n",
    "The image below shows a visualization (RGB) of the downloaded product 'S2A_MSIL1C_20180803T103021_N0500_R108_T32UNE_20230730T062418' in SNAP Desktop. We have a scene with mostly clear skies (few shallow clouds only) showing Hamburg and surrounding area.\n",
    "\n",
    "<img src=\"S2A_MSIL1C_20180803T103021_N0206_R108_T32UNE_20180803T142136_RGB.png\" alt=\"JupyterLab web page\" style=\"max-width: 100%; height: auto;\" width: auto>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c7914-ad2f-4385-9377-77f1ab5ab7f3",
   "metadata": {},
   "source": [
    "## **7. Example of a workflow using the SNAP API from Python**\n",
    "\n",
    "The following simple workflow example reads raster data from two bands (B4 and B8) of the downloaded S2 L1C product, computes/displays a simple NDVI, and saves the NDVI image as png. The SNAP core classes 'ProductIO' and 'Band' are accessed via the SNAP Python API 'Snappy'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96509c88-db67-458d-b160-329ec82e1b07",
   "metadata": {},
   "source": [
    "##### ***Some more imports:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e13d53-634f-4fe9-82f3-fee477038ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esa_snappy import ProductIO  \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5008b-a43d-4e38-879c-a611e83942d1",
   "metadata": {},
   "source": [
    "##### ***Read the data product into SNAP:***\n",
    "\n",
    "Info and warning messages can be ignored here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beded511-cef2-4de7-9eb5-d0a1b9d3981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ProductIO.readProduct(l1c_product_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae336a1-3107-40ff-854a-9344488d85d9",
   "metadata": {},
   "source": [
    "##### ***Print some information:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da173cf0-19e3-4d5e-91fd-df7d870cc05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of bands: ' + str(p.getNumBands()))\n",
    "\n",
    "b4 = p.getBand('B4')\n",
    "w = b4.getRasterWidth()\n",
    "h = b4.getRasterHeight()\n",
    "print('Band B4 Raster width: ' + str(b4.getRasterWidth()))\n",
    "print('Band B4 Raster height: ' + str(b4.getRasterHeight()))\n",
    "print('Band B4 Wavelength: ' + str(b4.getSpectralWavelength()))\n",
    "print('Band B4 Spectral bandwidth: ' + str(b4.getSpectralBandwidth()))\n",
    "\n",
    "b8 = p.getBand('B8')\n",
    "w = b8.getRasterWidth()\n",
    "h = b8.getRasterHeight()\n",
    "print('Band B8 Raster width: ' + str(b8.getRasterWidth()))\n",
    "print('Band B8 Raster height: ' + str(b8.getRasterHeight()))\n",
    "print('Band B8 Wavelength: ' + str(b8.getSpectralWavelength()))\n",
    "print('Band B8 Spectral bandwidth: ' + str(b8.getSpectralBandwidth()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb467ec1-e5e3-4095-9cf3-f227daf16e91",
   "metadata": {},
   "source": [
    "##### ***Consider a 2000x2000 subset covering the center of Hamburg:***\n",
    "\n",
    "If possible, using a subset of area of interest and required bands is always recommended. Processing full S2 products might be rather time and memory consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984be10a-d501-4e19-aaee-9080fb1af64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xoff = 5001\n",
    "yoff = 6001\n",
    "wsub = 2000\n",
    "hsub = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54357dff-7f20-407d-9064-3d59977503b2",
   "metadata": {},
   "source": [
    "##### ***Read the raster data into numpy arrays:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08130852-43f4-4cf8-a40c-45c0b5769368",
   "metadata": {},
   "outputs": [],
   "source": [
    "b4_data = np.zeros(wsub * hsub, np.float32)\n",
    "b4.readPixels(xoff, yoff, wsub, hsub, b4_data)\n",
    "b4_data.shape = hsub, wsub\n",
    "\n",
    "b8_data = np.zeros(wsub * hsub, np.float32)\n",
    "b8.readPixels(xoff, yoff, wsub, hsub, b8_data)\n",
    "b8_data.shape = hsub, wsub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92aa107-b45d-4fea-b831-e243c25df86b",
   "metadata": {},
   "source": [
    "##### ***Define a convenience function to plot NDVI:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64f979-80ff-4a6a-883a-a5686ea75d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ndvi(data):\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.set_title(\"NDVI\")\n",
    "    ndvi_image = ax1.imshow(data, cmap=mpl.colormaps['gray'], vmin=-0.2, vmax=1)\n",
    "    fig1.colorbar(ndvi_image)\n",
    "    return ndvi_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcbd8a1-4928-4a75-88f4-2673b9d90e0b",
   "metadata": {},
   "source": [
    "##### ***Compute NDVI:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71331389-93b8-45ef-8ec0-0454048ba99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_data = (b8_data - b4_data) / (b8_data + b4_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dbfd5e-9528-4a07-9d74-e9084191fcd5",
   "metadata": {},
   "source": [
    "##### ***Display B4, B8, NDVI data:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b1be8-e554-4cb3-9390-c7dc66894459",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, _axs = plt.subplots(nrows=1, ncols=2)\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "axs = _axs.flatten()\n",
    "\n",
    "axs[0].set_title(\"B4\")\n",
    "axs[0].tick_params(axis=\"both\", length=0, labelbottom=False, labelleft=False)\n",
    "axs[0].imshow(b4_data, cmap=mpl.colormaps['gray'], vmin=-0.1, vmax=0.5)\n",
    "\n",
    "axs[1].set_title(\"B8\")\n",
    "axs[1].tick_params(axis=\"both\", length=0, labelbottom=False, labelleft=False)\n",
    "axs[1].imshow(b8_data, cmap=mpl.colormaps['gray'], vmin=-0.1, vmax=0.5)\n",
    "\n",
    "plt.show(block=True)\n",
    "\n",
    "ndvi_image = plot_ndvi(ndvi_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a480676-974c-495a-a965-8af96dc1554e",
   "metadata": {},
   "source": [
    "##### ***Write NDVI to png file:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84aeb7b-d19f-485a-94fc-3bc56ac834e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_image.write_png('ndvi_full.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2560836a-3442-4d46-8695-3c92d1b14f62",
   "metadata": {},
   "source": [
    "##### ***Dispose the product:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013813f1-1c95-4022-bb80-64b53a08766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f17240-0020-412a-bd83-f783ec5f7d4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae5a7c0-c7a7-4b82-8f95-fca867134ada",
   "metadata": {},
   "source": [
    "## **8. Run the workflow using GPF and Snappy**\n",
    "\n",
    "In this section we basically run the same workflow, but with means of the SNAP Python API 'Snappy' together with the SNAP GPF framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2b03b-30b5-4135-93a6-f85f916dcc92",
   "metadata": {},
   "source": [
    "##### ***Some required imports from esa_snappy:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc735932-c0b9-4a61-8d51-3b3bf80efdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from esa_snappy import GPF\n",
    "from esa_snappy import HashMap\n",
    "from esa_snappy import Rectangle\n",
    "from esa_snappy import jpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0f1ba-1c00-4d8a-9824-d64df5557596",
   "metadata": {},
   "source": [
    "##### ***Read L1C product again into SNAP:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52470758-c98a-40b8-9cf7-98e33c5c5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ProductIO.readProduct(l1c_product_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f868c5c4-f074-4266-8b64-7304d6a595e7",
   "metadata": {},
   "source": [
    "##### ***Set up a 'Subset' operator which considers the rectangle defined above:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753a2e7-61ad-4fa1-bfdb-c34102bcfc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_op_name = 'Subset'\n",
    "subset_parameters = HashMap()\n",
    "subset_parameters.put('sourceBands', 'B4,B8')\n",
    "subset_rect = Rectangle(xoff,yoff,wsub,hsub)\n",
    "subset_parameters.put('region', subset_rect)\n",
    "subset_product = GPF.createProduct(subset_op_name, subset_parameters, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecabe28-45be-4ae8-a5d1-3704f63f0beb",
   "metadata": {},
   "source": [
    "##### ***Set up a 'BandMaths' operator to compute a simple NDVI. Set up a target band for NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d1b21-158c-4ad2-9554-56e87b6c7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bandmaths_op_name = 'BandMaths'\n",
    "BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "ndvi_band = BandDescriptor()\n",
    "ndvi_band.name = 'ndvi'\n",
    "ndvi_band.type = 'float32'\n",
    "ndvi_band.expression = '(B8 - B4)/(B8 + B4)'\n",
    "target_bands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', 1)\n",
    "target_bands[0] = ndvi_band\n",
    "bandmaths_parameters = HashMap()\n",
    "bandmaths_parameters.put('targetBands', target_bands)\n",
    "bandmaths_product = GPF.createProduct(bandmaths_op_name, bandmaths_parameters, subset_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a69f9e-423d-4e49-9d47-bd7edd5597d8",
   "metadata": {},
   "source": [
    "##### ***Additional step: Merge NDVI with bands of subset product :***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85e56d-4eaf-4693-afe4-2aa31c8a0cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_op_name = 'BandMerge'\n",
    "merge_parameters = HashMap()\n",
    "merge_parameters.put('sourceBands', 'B4,B8,ndvi')\n",
    "source_products = HashMap()\n",
    "source_products.put('Subset', subset_product)\n",
    "source_products.put('BandMaths', bandmaths_product)\n",
    "merge_product = GPF.createProduct(merge_op_name, merge_parameters, source_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4544c570-9fd0-4b4b-bc8d-0c9ff88edb03",
   "metadata": {},
   "source": [
    "##### ***Additional step: Write Merge Subset result into a NetCDF file. This file can be downloaded and e.g. opened and visualized in SNAP Desktop:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408132c-b95f-4454-8fcb-623d755ae550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductIO.writeProduct(merge_product, './ndvi_result_snappy.nc', 'NetCDF4-BEAM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f4df1-9b4e-43e5-8721-43f62ff1abdc",
   "metadata": {},
   "source": [
    "##### ***Display NDVI result:***\n",
    "\n",
    "We do a quick (visual) check if we have the same NDVI result as from 'pure Snappy' above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4f8c5-e6fa-42f9-adf1-80fa2da92baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = merge_product.getBand('ndvi')\n",
    "w = ndvi.getRasterWidth()\n",
    "h = ndvi.getRasterHeight()\n",
    "\n",
    "ndvi_data = np.zeros(w * h, np.float32)\n",
    "ndvi.readPixels(0, 0, w, h, ndvi_data)\n",
    "ndvi_data.shape = h, w\n",
    "\n",
    "ndvi_image = plot_ndvi(ndvi_data)\n",
    "\n",
    "ndvi_image.write_png('ndvi.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4780693-c4f8-43a4-87de-a3b4d1d8684b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd163ee4-5a8e-478c-86a9-1865f1709969",
   "metadata": {},
   "source": [
    "## **9. Run the workflow in an XML graph with SNAPISTA**\n",
    "\n",
    "In this section we run the same workflow once again, but with means of the SNAP Python API 'SNAPISTA' which since SNAP 12 is provided together with Snappy. The section will illustrate the capabilities of SNAPISTA to create, view, run and export SNAP GPT xml graphs in a very simple and user-friendly manner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb929180-78da-4706-ab2c-f0e823a06e3c",
   "metadata": {},
   "source": [
    "#### **Fill a SNAPISTA graph with nodes:**\n",
    "\n",
    "\n",
    "##### ***Initialize the graph:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b5bfb-1e2e-405d-8027-4a9a0acce844",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    g = Graph()\n",
    "except Exception as ex:\n",
    "    print(\"Cannot set up Snapista Graph():\", ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b97e0-b7cb-44e1-9427-cf9151ccd881",
   "metadata": {},
   "source": [
    "##### ***Read L1C product again into SNAP:***\n",
    "\n",
    "With a single line of Python code, a complete node can be created and added to a GPT graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f971b6ce-2fb4-4448-9730-7727863a49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.add_node(operator=Operator(\"Read\", file=l1c_product_to_process), node_id=\"Read_l1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6668d56e-a02a-4af9-a7e4-fcea6930143c",
   "metadata": {},
   "source": [
    "##### ***Set up a 'Subset' operator which considers the rectangle defined above:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a257860a-3118-4dd1-8eb9-1169dcbdd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_op = Operator('Subset', sourceBands=\"B4,B8\", region='5001, 6001, 2000, 2000')\n",
    "g.add_node(operator=subset_op, node_id=\"Subset\" ,source='Read_l1c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a5919-241b-47d1-b33f-d4d5626a34c4",
   "metadata": {},
   "source": [
    "##### ***Set up a 'BandMaths' operator to compute a simple NDVI. Set up a target band for NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dedcc3-698e-40cb-b1f2-97c6a1e3d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_maths_op = Operator('BandMaths')\n",
    "ndvi = TargetBand(name='ndvi', expression='(B8 - B4)/(B8 + B4)')\n",
    "band_maths_op.targetBandDescriptors = TargetBandDescriptors([ndvi])\n",
    "g.add_node(operator=band_maths_op, node_id=\"BandMaths\" ,source='Subset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86920a83-2ab5-4559-80ab-abb7ef2fdec5",
   "metadata": {},
   "source": [
    "##### ***Merge NDVI with bands of subset product:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fda0c1-bedc-44f8-8ed1-cb7bbdd00b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = Operator(\"BandMerge\", sourceBands=\"B4,B8,ndvi\")\n",
    "g.add_node(operator=merge, node_id=\"Merge\", source=[\"Subset\", \"BandMaths\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afc62a1-3207-4554-9b1e-80e41909c184",
   "metadata": {},
   "source": [
    "##### ***Write Merge Subset result into a file:***\n",
    "\n",
    "We use NetCDF4-BEAM as output format. Any other format supported by SNAP could be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e251c8-24d5-4d8b-a4d0-ef53a32a1712",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ndvi = Operator(\"Write\", file='./ndvi_result_snapista.nc', formatName='NetCDF4-BEAM')\n",
    "g.add_node(operator=write_ndvi, node_id=\"WriteNdvi\", source='Merge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d44e21-bd0c-4648-b9d7-cc5a0dedd256",
   "metadata": {},
   "source": [
    "##### ***Display the graph:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7578a0-49f1-4a24-8312-fdc582c67204",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168f88d-dbcb-4ff2-9b98-366ce22ec7e2",
   "metadata": {},
   "source": [
    "##### ***Export the graph:***\n",
    "\n",
    "The graph can be saved to disk as xml fie. Then, for example, it could be executed with the SNAP 'gpt' command from the command line or in a batch processing chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8deaff2-13db-42de-a846-c521c7a974f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.save_graph('./lps_workflow_example_graph.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad2b1ec-6e48-4e7d-929a-d2cfe1d3309f",
   "metadata": {},
   "source": [
    "##### ***Run the graph:***\n",
    "\n",
    "However, we can run the graph here, as SNAPISTA provides a very simple wrapper for the SNAP 'gpt' command to run the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf9334a-3bd6-45c7-83d9-832297de04f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbd90bb-4960-4ecd-9bf9-91c379b5437d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb3c8c-69a1-42fb-8b08-5af1e26ed367",
   "metadata": {},
   "source": [
    "## **10. Compare SNAPISTA NDVI result with the one from Snappy**\n",
    "\n",
    "Again, we do a quick (visual) check if the SNAPISTA graph process produced the same NDVI result as 'pure Snappy' and 'Snappy with GPF' above. \n",
    "\n",
    "##### ***Read SNAPISTA NDVI result NetCDF back into SNAP:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf96cdb9-4559-47c0-9e4d-1b914276097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_snapista_product = ProductIO.readProduct('./ndvi_result_snapista.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259850f-d069-4ece-a28a-500fe7017237",
   "metadata": {},
   "source": [
    "##### ***Display NDVI result:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce7d99-2bb1-42f3-833e-68e30aa2aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = ndvi_snapista_product.getBand('ndvi')\n",
    "w = ndvi.getRasterWidth()\n",
    "h = ndvi.getRasterHeight()\n",
    "\n",
    "ndvi_data = np.zeros(w * h, np.float32)\n",
    "ndvi.readPixels(0, 0, w, h, ndvi_data)\n",
    "ndvi_data.shape = h, w\n",
    "\n",
    "plot_ndvi(ndvi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd7bac-bfc1-4f90-b747-3bc9673b0b15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c0cbe-dd79-4a56-9759-48d4bb994cd2",
   "metadata": {},
   "source": [
    "## **11. Cleanup**\n",
    "Before ending the notebook, we remove the downloaded source product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256f7ba-ca16-49fe-aac2-0ae53e9d0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cleanup...')\n",
    "subprocess.call([\"rm\", \"-Rf\", l1c_product_to_process])\n",
    "\n",
    "print('Notebook finished successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48566d9-ab6b-433a-8bc4-e0b8e6dd0797",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26beb688-2a1f-4210-85a0-33eb23f8f539",
   "metadata": {},
   "source": [
    "## **12. Summary**\n",
    "\n",
    "What have we learnt in this notebook?\n",
    "\n",
    "- How to quickly access satellite imagery using STAC Catalogue API and S3 download.\n",
    "- How to read a Sentinel-2 L1C product into SNAP\n",
    "- How to build and run a SNAP gpt graph using SNAP Python API (esa_snappy, Snapista)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
